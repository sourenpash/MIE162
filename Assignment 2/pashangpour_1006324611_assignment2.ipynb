{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "number of responses per class per quesiton"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the clean dataset with explicit encoding\n",
    "df = pd.read_csv('clean_kaggle_data_2022.csv', encoding='ISO-8859-1')\n",
    "df_head = pd.read_csv('clean_kaggle_data_2022.csv', encoding='ISO-8859-1', nrows=1)\n",
    "\n",
    "# Get the first row as column names\n",
    "column_names=df_head.columns.tolist()\n",
    "\n",
    "# Drop the first two rows (header and unit information)\n",
    "df = df[2:]\n",
    "\n",
    "# Set the column names\n",
    "df.columns = column_names\n",
    "\n",
    "# Iterate through each column starting from the second column (index 1)\n",
    "response_tally = []\n",
    "\n",
    "for column in df.columns[1:]:\n",
    "    responses = df[column].value_counts().reset_index()\n",
    "    responses.columns = ['Response', 'Count']\n",
    "    responses['Column'] = column\n",
    "    response_tally.append(responses)\n",
    "\n",
    "# Concatenate the response tally dataframes\n",
    "result_df = pd.concat(response_tally, ignore_index=True)\n",
    "\n",
    "# Save the result to an Excel file\n",
    "result_df.to_excel('numberOfResponsesPerClass.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": [
     "number of classes per question"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "df = pd.read_excel('response_tally.xlsx')\n",
    "\n",
    "# Initialize an empty dictionary to hold string tallies\n",
    "column_tally = {}\n",
    "\n",
    "# Loop through each row in the \"Column\" column\n",
    "for item in df['Column']:\n",
    "    if item in column_tally:\n",
    "        column_tally[item] += 1                        \n",
    "    else:\n",
    "        column_tally[item] = 1\n",
    "\n",
    "# Convert the column tally dictionary to a DataFrame\n",
    "output_df = pd.DataFrame(list(column_tally.items()), columns=['Column', 'Tally'])\n",
    "\n",
    "# Save the DataFrame to a new Excel file\n",
    "output_df.to_excel('numberOfclassesPerQuestion.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\souren\\AppData\\Local\\Temp\\ipykernel_22844\\2203218641.py:11: DtypeWarning: Columns (0,15,43,57,73,88,104,118,126,132,170,200,215,248,272,281,294) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('clean_kaggle_data_2022.csv')\n",
      "C:\\Users\\souren\\AppData\\Local\\Temp\\ipykernel_22844\\2203218641.py:14: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna('unknown', inplace=True)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\MIE162\\MIE162\\Assignment 2\\pashangpour_1006324611_assignment2.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#W2sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mnan\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#W2sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m# Apply the function to the target variable\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#W2sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m y_train \u001b[39m=\u001b[39m y_train\u001b[39m.\u001b[39;49mapply(encode_salary)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#W2sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m y_test \u001b[39m=\u001b[39m y_test\u001b[39m.\u001b[39mapply(encode_salary)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#W2sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m nan_indices \u001b[39m=\u001b[39m y_train[y_train\u001b[39m.\u001b[39misna()]\u001b[39m.\u001b[39mindex\n",
      "File \u001b[1;32mc:\\Program Files\\anaconda3\\envs\\MIE162\\Lib\\site-packages\\pandas\\core\\series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4626\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4632\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4633\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4634\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4635\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4751\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4752\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4753\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4754\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   4755\u001b[0m         func,\n\u001b[0;32m   4756\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n\u001b[0;32m   4757\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n\u001b[0;32m   4758\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   4759\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m-> 4760\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Program Files\\anaconda3\\envs\\MIE162\\Lib\\site-packages\\pandas\\core\\apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[0;32m   1206\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1207\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Program Files\\anaconda3\\envs\\MIE162\\Lib\\site-packages\\pandas\\core\\apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n\u001b[0;32m   1288\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n\u001b[0;32m   1289\u001b[0m )\n\u001b[0;32m   1291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1292\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Program Files\\anaconda3\\envs\\MIE162\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
      "File \u001b[1;32mc:\\Program Files\\anaconda3\\envs\\MIE162\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n\u001b[0;32m   1815\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2917\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32md:\\MIE162\\MIE162\\Assignment 2\\pashangpour_1006324611_assignment2.ipynb Cell 3\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#W2sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m350000\u001b[39m  \u001b[39m# or you can use 300000\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#W2sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39melif\u001b[39;00m salary \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39munknown\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#W2sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mnan  \u001b[39m# you can later decide to fill these NaNs or drop them\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#W2sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#W2sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mnan\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from category_encoders import BinaryEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('clean_kaggle_data_2022.csv')\n",
    "\n",
    "# Handling missing values by filling 'null' with 'unknown'\n",
    "df.fillna('unknown', inplace=True)\n",
    "\n",
    "# Encoding categorical features\n",
    "\n",
    "# Initialize label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# List of questions to be label encoded\n",
    "label_encoding_questions = ['Q2', 'Q11', 'Q16', 'Q25', 'Q26', 'Q30', 'Q43']\n",
    "for question in label_encoding_questions:\n",
    "    # Encode only if the column exists in the DataFrame\n",
    "    if question in df.columns:\n",
    "        df[question] = label_encoder.fit_transform(df[question])\n",
    "\n",
    "# Binary encoding for Q9\n",
    "binary_encoder = BinaryEncoder(cols=['Q9'])\n",
    "df = binary_encoder.fit_transform(df)\n",
    "\n",
    "# Remove Q5 as per the instructions\n",
    "df.drop('Q5', axis=1, inplace=True)\n",
    "\n",
    "# One-hot encoding for the rest of the columns, except already encoded ones\n",
    "one_hot_encoding_questions = [col for col in df.columns if col not in label_encoding_questions and col != 'Q9']\n",
    "df = pd.get_dummies(df, columns=one_hot_encoding_questions)\n",
    "\n",
    "# Handle the target 'Q29_buckets'\n",
    "target_columns = [col for col in df.columns if 'Q29_buckets_' in col]\n",
    "if target_columns:\n",
    "    # Revert one-hot encoding for the target\n",
    "    y = df[target_columns].idxmax(axis=1).str.replace('Q29_buckets_', '')\n",
    "    X = df.drop(columns=target_columns)\n",
    "else:\n",
    "    X = df.drop('Q29_buckets', axis=1, errors='ignore')\n",
    "    y = df['Q29_buckets']\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Using RandomForest to measure feature importance\n",
    "def encode_salary(salary):\n",
    "    \"\"\"\n",
    "    Convert salary range strings into their midpoint values for regression modeling.\n",
    "    \"\"\"\n",
    "    if '-' in salary:\n",
    "        lower, upper = salary.split('-')\n",
    "        lower = int(lower.replace(',', ''))\n",
    "        upper = int(upper.replace(',', ''))\n",
    "        return (lower + upper) / 2\n",
    "    elif salary == '>300,000':\n",
    "        return 350000  # or you can use 300000\n",
    "    elif salary == 'unknown':\n",
    "        return np.nan  # you can later decide to fill these NaNs or drop them\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to the target variable\n",
    "y_train = y_train.apply(encode_salary)\n",
    "y_test = y_test.apply(encode_salary)\n",
    "\n",
    "nan_indices = y_train[y_train.isna()].index\n",
    "y_train.drop(nan_indices, inplace=True)\n",
    "X_train.drop(nan_indices, inplace=True)\n",
    "\n",
    "# Now, fit the RandomForest\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the importance of each feature\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame for the importances\n",
    "features_df = pd.DataFrame({\n",
    "    'Features': X_train.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame based on importance\n",
    "features_df = features_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plotting the feature importances\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.barplot(data=features_df.iloc[:15], x='Features', y='Importance') # showing top 15 features\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Top 15 Important Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize a scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mord\n",
    "\n",
    "# Initialize an ordinal logistic regression model\n",
    "ord_logit = mord.LogisticAT() # LogisticAT is one of the types of ordinal logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Updated mapping of salary midpoints to integer labels\n",
    "salary_to_int = {\n",
    "    4999.5: 0,\n",
    "    14999.5: 1,\n",
    "    24999.5: 2,\n",
    "    34999.5: 3,\n",
    "    44999.5: 4,\n",
    "    54999.5: 5,\n",
    "    64999.5: 6,\n",
    "    74999.5: 7,\n",
    "    84999.5: 8,\n",
    "    94999.5: 9,\n",
    "    112499.5: 10,\n",
    "    137499.5: 11,\n",
    "    174999.5: 12,\n",
    "    249999.5: 13,\n",
    "    350000.0: 14,  # This represents >300,000 as it's the upper limit\n",
    "    'unknown': 15\n",
    "}\n",
    "\n",
    "# Map the encoded salaries to integers\n",
    "y_train_int = y_train.map(salary_to_int)\n",
    "y_test_int = y_test.map(salary_to_int)\n",
    "\n",
    "# Ensure no NaN values in the mapped labels\n",
    "assert y_train_int.isna().sum() == 0, \"NaN values exist in y_train_int\"\n",
    "assert y_test_int.isna().sum() == 0, \"NaN values exist in y_test_int\"\n",
    "\n",
    "# Apply ordinal logistic regression on the integer labels\n",
    "accuracies = cross_val_score(ord_logit, X_train_scaled, y_train_int, cv=10)\n",
    "\n",
    "# Average and variance of accuracy\n",
    "avg_accuracy = accuracies.mean()\n",
    "var_accuracy = accuracies.var()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\MIE162\\MIE162\\Assignment 2\\pashangpour_1006324611_assignment2.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m make_scorer, f1_score\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m GridSearchCV\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjoblib\u001b[39;00m  \u001b[39m# Import joblib for model saving\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\anaconda3\\envs\\MIE162\\Lib\\site-packages\\sklearn\\__init__.py:83\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[39m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[39m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     \u001b[39m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     80\u001b[0m         __check_build,  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         _distributor_init,  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     )\n\u001b[1;32m---> 83\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m clone\n\u001b[0;32m     84\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_show_versions\u001b[39;00m \u001b[39mimport\u001b[39;00m show_versions\n\u001b[0;32m     86\u001b[0m     __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     87\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcalibration\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     88\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcluster\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mshow_versions\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    130\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Program Files\\anaconda3\\envs\\MIE162\\Lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_config\u001b[39;00m \u001b[39mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_estimator_html_repr\u001b[39;00m \u001b[39mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_metadata_requests\u001b[39;00m \u001b[39mimport\u001b[39;00m _MetadataRequester\n",
      "File \u001b[1;32mc:\\Program Files\\anaconda3\\envs\\MIE162\\Lib\\site-packages\\sklearn\\utils\\__init__.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_bunch\u001b[39;00m \u001b[39mimport\u001b[39;00m Bunch\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_estimator_html_repr\u001b[39;00m \u001b[39mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_param_validation\u001b[39;00m \u001b[39mimport\u001b[39;00m Interval, validate_params\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mclass_weight\u001b[39;00m \u001b[39mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdeprecation\u001b[39;00m \u001b[39mimport\u001b[39;00m deprecated\n",
      "File \u001b[1;32mc:\\Program Files\\anaconda3\\envs\\MIE162\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_config\u001b[39;00m \u001b[39mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvalidation\u001b[39;00m \u001b[39mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[0;32m     18\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mInvalidParameterError\u001b[39;00m(\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m     19\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39m    does not have a valid type or value.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\anaconda3\\envs\\MIE162\\Lib\\site-packages\\sklearn\\utils\\validation.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m get_config \u001b[39mas\u001b[39;00m _get_config\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_array_api\u001b[39;00m \u001b[39mimport\u001b[39;00m _asarray_with_order, _is_numpy_namespace, get_namespace\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfixes\u001b[39;00m \u001b[39mimport\u001b[39;00m ComplexWarning\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_isfinite\u001b[39;00m \u001b[39mimport\u001b[39;00m FiniteStatus, cy_isfinite\n",
      "File \u001b[1;32mc:\\Program Files\\anaconda3\\envs\\MIE162\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspecial\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mspecial\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_config\u001b[39;00m \u001b[39mimport\u001b[39;00m get_config\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfixes\u001b[39;00m \u001b[39mimport\u001b[39;00m parse_version\n\u001b[0;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_array_api_dispatch\u001b[39m(array_api_dispatch):\n\u001b[0;32m     13\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that array_api_compat is installed and NumPy version is compatible.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[39m    array_api_compat follows NEP29, which has a higher minimum NumPy version than\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m    scikit-learn.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\anaconda3\\envs\\MIE162\\Lib\\site-packages\\sklearn\\utils\\fixes.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinalg\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mthreadpoolctl\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msklearn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\anaconda3\\envs\\MIE162\\Lib\\site-packages\\scipy\\stats\\__init__.py:608\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m \n\u001b[0;32m    604\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    606\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_warnings_errors\u001b[39;00m \u001b[39mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    607\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 608\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stats_py\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    609\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_variation\u001b[39;00m \u001b[39mimport\u001b[39;00m variation\n\u001b[0;32m    610\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdistributions\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Program Files\\anaconda3\\envs\\MIE162\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspecial\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mspecial\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m \u001b[39mimport\u001b[39;00m linalg\n\u001b[1;32m---> 46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m distributions\n\u001b[0;32m     47\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _mstats_basic \u001b[39mas\u001b[39;00m mstats_basic\n\u001b[0;32m     48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stats_mstats_common\u001b[39;00m \u001b[39mimport\u001b[39;00m (_find_repeats, linregress, theilslopes,\n\u001b[0;32m     49\u001b[0m                                    siegelslopes)\n",
      "File \u001b[1;32mc:\\Program Files\\anaconda3\\envs\\MIE162\\Lib\\site-packages\\scipy\\stats\\distributions.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_distn_infrastructure\u001b[39;00m \u001b[39mimport\u001b[39;00m (rv_discrete, rv_continuous, rv_frozen)  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _continuous_distns\n\u001b[1;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _discrete_distns\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_continuous_distns\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_levy_stable\u001b[39;00m \u001b[39mimport\u001b[39;00m levy_stable\n",
      "File \u001b[1;32mc:\\Program Files\\anaconda3\\envs\\MIE162\\Lib\\site-packages\\scipy\\stats\\_discrete_distns.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspecial\u001b[39;00m \u001b[39mimport\u001b[39;00m entr, logsumexp, betaln, gammaln \u001b[39mas\u001b[39;00m gamln, zeta\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_lib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_util\u001b[39;00m \u001b[39mimport\u001b[39;00m _lazywhere, rng_integers\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minterpolate\u001b[39;00m \u001b[39mimport\u001b[39;00m interp1d\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mimport\u001b[39;00m floor, ceil, log, exp, sqrt, log1p, expm1, tanh, cosh, sinh\n\u001b[0;32m     14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\anaconda3\\envs\\MIE162\\Lib\\site-packages\\scipy\\interpolate\\__init__.py:167\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m========================================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mInterpolation (:mod:`scipy.interpolate`)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[39m(should not be used in new code).\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_interpolate\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    168\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_fitpack_py\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    170\u001b[0m \u001b[39m# New interface to fitpack library:\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\anaconda3\\envs\\MIE162\\Lib\\site-packages\\scipy\\interpolate\\_interpolate.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m dfitpack\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_polyint\u001b[39;00m \u001b[39mimport\u001b[39;00m _Interpolator1D\n\u001b[1;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _ppoly\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39minterpnd\u001b[39;00m \u001b[39mimport\u001b[39;00m _ndim_coords_from_arrays\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_bsplines\u001b[39;00m \u001b[39mimport\u001b[39;00m make_interp_spline, BSpline\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:405\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib  # Import joblib for model saving\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'max_iter': [100, 500, 1000, 5000]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with f1_score as the scoring metric\n",
    "grid_search = GridSearchCV(\n",
    "    ord_logit,\n",
    "    param_grid,\n",
    "    cv=10,\n",
    "    scoring=make_scorer(f1_score, average='micro'),  # f1_score micro is a good general choice\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_scaled, y_train_int)\n",
    "\n",
    "# Extract best hyperparameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Print out the best parameters\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Save the best model to disk using joblib\n",
    "joblib.dump(best_model, 'best_ordinal_logit_model.joblib')\n",
    "\n",
    "# Optional: Load the model later using joblib\n",
    "# loaded_model = joblib.load('best_ordinal_logit_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\MIE162\\MIE162\\Assignment 2\\pashangpour_1006324611_assignment2.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Assuming you've performed grid search and got the best_model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Extract coefficients (since it's scalar, it will be the same for all features)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m coef_scalar \u001b[39m=\u001b[39m best_model\u001b[39m.\u001b[39mcoef_\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Feature names\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MIE162/MIE162/Assignment%202/pashangpour_1006324611_assignment2.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m features \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mcolumns\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you've performed grid search and got the best_model\n",
    "\n",
    "# Extract coefficients (since it's scalar, it will be the same for all features)\n",
    "coef_scalar = best_model.coef_\n",
    "\n",
    "# Feature names\n",
    "features = X_train.columns\n",
    "\n",
    "# Generate a list with the scalar repeated for all features (since it's constant for all)\n",
    "importance = [coef_scalar] * len(features)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Feature Importance (using coefficient magnitude)')\n",
    "plt.barh(features, importance, align='center')\n",
    "plt.xlabel('Coefficient Magnitude')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmapped categories: [ 34999.5 112499.5  94999.5   4999.5 249999.5  44999.5  24999.5 174999.5\n",
      "  74999.5  54999.5  14999.5  64999.5 350000.  137499.5  84999.5]\n"
     ]
    }
   ],
   "source": [
    "# Identify the unmatched categories in y_train\n",
    "unmatched_categories = y_train[y_train_int.isna()].unique()\n",
    "\n",
    "print(\"Unmapped categories:\", unmatched_categories)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIE162",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
